{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "sys.path.append('util')\n",
    "from camera_utils import process_camera_json, world_to_pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrin, extrin, extrin_inv = process_camera_json('content2/slahmr/outputs/logs/video-val/2024-03-10/shorto-all-shot-0-0-180/smooth_fit/shorto_cameras_000060.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5e+03 0.0e+00 9.6e+02]\n",
      " [0.0e+00 1.5e+03 5.4e+02]\n",
      " [0.0e+00 0.0e+00 1.0e+00]]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(intrin)\n",
    "\n",
    "print(extrin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3)\n",
      "[ 3.84636    -0.82861257 12.2781515 ]\n",
      "[1429.90297738  438.76987202]\n"
     ]
    }
   ],
   "source": [
    "smoothed_file = 'content2/slahmr/outputs/logs/video-val/2024-03-10/shorto-all-shot-0-0-180/smooth_fit/shorto_000060_world_results.npz'\n",
    "smoothed_data = np.load(smoothed_file)\n",
    "transformations = smoothed_data['trans']\n",
    "root_orient = smoothed_data['root_orient']\n",
    "\n",
    "# Ped 0 step 0\n",
    "ped_0_poses = transformations[1,:,:]\n",
    "print(ped_0_poses.shape)\n",
    "print(ped_0_poses[100])\n",
    "# Convert world to pixel\n",
    "intrin = np.array(intrin)\n",
    "u_v = intrin @ ped_0_poses[100].T\n",
    "u_v = u_v / u_v[2]\n",
    "u_v = u_v[:2]\n",
    "print(u_v)\n",
    "\n",
    "# get \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "6 7\n",
      "6 8\n",
      "6 9\n",
      "6 10\n",
      "6 11\n",
      "9 0\n",
      "9 1\n",
      "9 2\n",
      "9 3\n",
      "9 4\n",
      "9 5\n",
      "9 6\n",
      "9 7\n",
      "9 8\n",
      "9 9\n",
      "9 10\n",
      "9 11\n",
      "10 133\n",
      "10 134\n",
      "10 135\n",
      "10 136\n",
      "10 137\n",
      "10 138\n",
      "10 139\n",
      "10 140\n",
      "10 141\n",
      "10 142\n",
      "10 143\n",
      "10 144\n",
      "10 145\n",
      "10 146\n",
      "10 147\n",
      "10 148\n",
      "10 149\n",
      "11 132\n",
      "11 133\n",
      "11 134\n",
      "11 135\n",
      "11 136\n",
      "11 137\n",
      "11 138\n",
      "11 139\n",
      "11 140\n",
      "11 141\n",
      "11 142\n",
      "11 143\n",
      "11 144\n",
      "11 145\n",
      "11 146\n",
      "11 147\n",
      "11 148\n",
      "11 149\n",
      "(12, 150, 2)\n"
     ]
    }
   ],
   "source": [
    "transformations = smoothed_data['trans']\n",
    "\n",
    "# Make uv empty array to store pixel coordinates\n",
    "# should produce a (N,T,2) array\n",
    "\n",
    "uv_transformations = np.zeros((transformations.shape[0], transformations.shape[1], 2))\n",
    "\n",
    "# get u_v for (N,T,3) transformations array\n",
    "\n",
    "for n in range(transformations.shape[0]):\n",
    "    for t in range(transformations.shape[1]):\n",
    "        u_v = intrin @ transformations[n,t].T\n",
    "        u_v = u_v / np.abs(u_v[2])\n",
    "        u_v = u_v[:2]\n",
    "\n",
    "        if u_v[0] < 0 or u_v[0] > 1920 or u_v[1] < 0 or u_v[1] > 1080:\n",
    "            print(n,t)\n",
    "        #     u_v = np.array([-1,-1])\n",
    "\n",
    "        uv_transformations[n,t] = u_v\n",
    "\n",
    "        \n",
    "\n",
    "print(uv_transformations.shape)\n",
    "\n",
    "def pixel_to_3d_point(u, v, Z, fx, fy, cx, cy):\n",
    "    \"\"\"\n",
    "    Convert a pixel coordinate (u, v) with a given depth Z to a 3D point in camera coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - u, v: Pixel coordinates in the image.\n",
    "    - Z: Depth value at the pixel (u, v).\n",
    "    - fx, fy: Focal lengths of the camera along the x and y axes.\n",
    "    - cx, cy: Coordinates of the principal point (typically the image center).\n",
    "\n",
    "    Returns:\n",
    "    - A tuple (X, Y, Z) representing the 3D point in camera coordinates.\n",
    "    \"\"\"\n",
    "    # Normalize pixel coordinates\n",
    "    x = (u - cx) / fx\n",
    "    y = (v - cy) / fy\n",
    "\n",
    "    # Apply depth to get 3D point\n",
    "    X = x * Z\n",
    "    Y = y * Z\n",
    "\n",
    "    return (X, Y, Z)\n",
    "\n",
    "\n",
    "\n",
    "# Save the transformations and uv_transformations to a new npz file\n",
    "np.savez('shorto_000060_pixel_results.npz', uv_transformations=uv_transformations, transformations=transformations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  877.44273748,   326.76543872],\n",
       "        [  875.50791799,   327.73540739],\n",
       "        [  873.01066407,   329.92618062],\n",
       "        ...,\n",
       "        [  299.74278492,   633.12114362],\n",
       "        [  293.8320895 ,   634.52657492],\n",
       "        [  289.43815459,   635.2934689 ]],\n",
       "\n",
       "       [[  908.88895033,   578.11658754],\n",
       "        [  914.23526949,   575.14372349],\n",
       "        [  920.61153113,   573.25003464],\n",
       "        ...,\n",
       "        [ 1580.44493608,   365.6896288 ],\n",
       "        [ 1582.28244988,   364.62214875],\n",
       "        [ 1583.63094548,   364.14309268]],\n",
       "\n",
       "       [[ 1316.33028323,   308.45034609],\n",
       "        [ 1315.02632273,   308.66994423],\n",
       "        [ 1313.62767533,   309.42425587],\n",
       "        ...,\n",
       "        [  959.42996929,   591.37338396],\n",
       "        [  957.96423259,   593.536142  ],\n",
       "        [  956.63551577,   594.95339146]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ -117.85728782, -1385.21539891],\n",
       "        [ -112.93892865, -1427.74967755],\n",
       "        [ -130.62163157, -1428.97959812],\n",
       "        ...,\n",
       "        [ 1029.19095991,   178.75679052],\n",
       "        [ 1027.54480016,   179.18161944],\n",
       "        [ 1026.52390647,   179.4925862 ]],\n",
       "\n",
       "       [[  791.55304713,   338.80902588],\n",
       "        [  793.05461436,   338.21895   ],\n",
       "        [  795.15823446,   337.7626621 ],\n",
       "        ...,\n",
       "        [ -302.36653878, -1033.56018076],\n",
       "        [ -302.65586136, -1031.23310026],\n",
       "        [ -303.69102107, -1029.50447565]],\n",
       "\n",
       "       [[ 1067.36575749,   157.68976252],\n",
       "        [ 1068.12351611,   156.97975386],\n",
       "        [ 1069.26973822,   156.58350985],\n",
       "        ...,\n",
       "        [ -302.36653878, -1033.56018076],\n",
       "        [ -302.65586136, -1031.23310026],\n",
       "        [ -303.69102107, -1029.50447565]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uv_transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 150, 2)\n"
     ]
    }
   ],
   "source": [
    "# read the npz file\n",
    "data = np.load('shorto_000060_pixel_results.npz')\n",
    "print(data['uv_transformations'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0: [908.88895033 578.11658754]\n",
      "Frame 1: [914.23526949 575.14372349]\n",
      "Frame 2: [920.61153113 573.25003464]\n",
      "Frame 3: [926.90911065 571.56424957]\n",
      "Frame 4: [932.66265833 570.0687749 ]\n",
      "Frame 5: [938.50629425 569.4820293 ]\n",
      "Frame 6: [945.07149115 569.59231034]\n",
      "Frame 7: [951.36553901 570.50738763]\n",
      "Frame 8: [957.44474139 572.02264297]\n",
      "Frame 9: [963.02000341 572.64674783]\n",
      "Frame 10: [969.01092438 571.74990719]\n",
      "Frame 11: [975.54815855 570.43941775]\n",
      "Frame 12: [982.35281056 568.52012323]\n",
      "Frame 13: [988.64282406 566.16235224]\n",
      "Frame 14: [994.95800694 564.451098  ]\n",
      "Frame 15: [1001.06039942  562.49090564]\n",
      "Frame 16: [1006.51900518  560.98563402]\n",
      "Frame 17: [1012.1557164   559.66306127]\n",
      "Frame 18: [1017.65152978  559.01731322]\n",
      "Frame 19: [1023.85164333  558.64295127]\n",
      "Frame 20: [1030.28382705  558.45913325]\n",
      "Frame 21: [1036.80028342  558.59708524]\n",
      "Frame 22: [1043.29806975  557.99667796]\n",
      "Frame 23: [1049.80466873  556.92696431]\n",
      "Frame 24: [1057.29768608  555.2948672 ]\n",
      "Frame 25: [1064.87942341  553.69260438]\n",
      "Frame 26: [1072.04654506  551.40293919]\n",
      "Frame 27: [1078.55123533  549.39162073]\n",
      "Frame 28: [1084.87265239  547.67287375]\n",
      "Frame 29: [1090.93312994  546.59071669]\n",
      "Frame 30: [1096.70428632  545.73270566]\n",
      "Frame 31: [1102.76845786  544.6885294 ]\n",
      "Frame 32: [1108.71713992  544.02965749]\n",
      "Frame 33: [1114.52855393  543.82611035]\n",
      "Frame 34: [1120.31550511  543.08493087]\n",
      "Frame 35: [1125.96560202  542.33153753]\n",
      "Frame 36: [1131.60874932  541.09820374]\n",
      "Frame 37: [1136.6145513   538.88792904]\n",
      "Frame 38: [1142.59200093  537.29252448]\n",
      "Frame 39: [1149.24709696  533.5150567 ]\n",
      "Frame 40: [1154.94898549  530.7239311 ]\n",
      "Frame 41: [1159.8088327   528.13004521]\n",
      "Frame 42: [1164.47924183  526.18018765]\n",
      "Frame 43: [1169.00598012  525.19136761]\n",
      "Frame 44: [1173.64018423  523.73528763]\n",
      "Frame 45: [1179.00426931  523.36435129]\n",
      "Frame 46: [1184.53027013  523.03551677]\n",
      "Frame 47: [1190.05105864  522.38517712]\n",
      "Frame 48: [1195.69917415  521.15655734]\n",
      "Frame 49: [1201.70164006  519.61560153]\n",
      "Frame 50: [1207.60679315  517.71998583]\n",
      "Frame 51: [1214.21636507  515.80278425]\n",
      "Frame 52: [1221.0555863   513.37989696]\n",
      "Frame 53: [1227.15861277  510.87838777]\n",
      "Frame 54: [1232.66059301  508.53581002]\n",
      "Frame 55: [1238.56164127  506.22587303]\n",
      "Frame 56: [1243.95697065  503.7454345 ]\n",
      "Frame 57: [1249.1296093   501.73469247]\n",
      "Frame 58: [1253.93813537  500.12905351]\n",
      "Frame 59: [1260.4473      494.31622005]\n",
      "Frame 60: [1266.35729136  489.28808268]\n",
      "Frame 61: [1270.73441551  486.72578448]\n",
      "Frame 62: [1274.47416341  486.26125673]\n",
      "Frame 63: [1278.72612534  483.90170763]\n",
      "Frame 64: [1283.08185809  484.04150951]\n",
      "Frame 65: [1286.4250978   485.02056186]\n",
      "Frame 66: [1289.79293246  485.9880503 ]\n",
      "Frame 67: [1293.92618975  484.85960476]\n",
      "Frame 68: [1298.25257441  483.39079664]\n",
      "Frame 69: [1302.54567443  482.26782959]\n",
      "Frame 70: [1306.6135769   481.58154594]\n",
      "Frame 71: [1311.113144    481.10727261]\n",
      "Frame 72: [1315.2373088   480.66016399]\n",
      "Frame 73: [1319.48076348  480.05394624]\n",
      "Frame 74: [1323.97964618  478.95240596]\n",
      "Frame 75: [1328.43410294  477.3600942 ]\n",
      "Frame 76: [1333.6583911   475.53522033]\n",
      "Frame 77: [1339.06205868  473.49077189]\n",
      "Frame 78: [1344.55992517  471.21291042]\n",
      "Frame 79: [1349.46589011  468.83565106]\n",
      "Frame 80: [1354.00808817  466.5264878 ]\n",
      "Frame 81: [1358.55374342  464.42148669]\n",
      "Frame 82: [1362.72217939  462.97450819]\n",
      "Frame 83: [1366.96233446  461.40090584]\n",
      "Frame 84: [1371.18208333  460.65476451]\n",
      "Frame 85: [1374.94109577  459.9159864 ]\n",
      "Frame 86: [1378.54332857  459.10924744]\n",
      "Frame 87: [1382.52606565  457.96781957]\n",
      "Frame 88: [1386.40408492  456.47095033]\n",
      "Frame 89: [1390.43475808  454.58441915]\n",
      "Frame 90: [1394.40517971  452.39306807]\n",
      "Frame 91: [1398.26051324  450.03780594]\n",
      "Frame 92: [1401.60883273  447.70406784]\n",
      "Frame 93: [1404.99967778  445.78859656]\n",
      "Frame 94: [1408.66476941  443.87258596]\n",
      "Frame 95: [1412.28761497  442.46655173]\n",
      "Frame 96: [1415.82775721  441.40736793]\n",
      "Frame 97: [1419.37351955  440.97786624]\n",
      "Frame 98: [1422.73025301  440.54490201]\n",
      "Frame 99: [1426.16932695  439.75640164]\n",
      "Saved GIF to ped_0_pose.gif\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "# Initialize video capture\n",
    "video = 'content2/slahmr/outputs/logs/video-val/2024-03-10/shorto-all-shot-0-0-180/shorto_input_final_000000_src_cam.mp4'  # Update this to the correct path\n",
    "cap = cv2.VideoCapture(video)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Error opening video stream or file\")\n",
    "\n",
    "# Prepare for GIF creation\n",
    "frames_for_gif = []\n",
    "\n",
    "# Process each frame\n",
    "frame_idx = 0\n",
    "for frame_idx in range(100):\n",
    "\n",
    "    # Get ped_0's pose for the current frame in world coordinates\n",
    "    ped_0_world_pose = transformations[1][frame_idx]\n",
    "    \n",
    "    # Convert world coordinates to pixel coordinates\n",
    "    ped_0_pixel_pose = world_to_pixel(ped_0_world_pose, intrin)\n",
    "    \n",
    "    print(f\"Frame {frame_idx}: {ped_0_pixel_pose}\")\n",
    "\n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "\n",
    "    # Draw the pose on the frame\n",
    "    cv2.circle(frame, tuple(ped_0_pixel_pose.astype(int)), 5, (0, 0, 255), -1)\n",
    "\n",
    "    # Append the frame to the list of frames for the GIF\n",
    "    frames_for_gif.append(frame)\n",
    "\n",
    "# Save the GIF\n",
    "gif_path = 'ped_0_pose.gif'\n",
    "imageio.mimsave(gif_path, frames_for_gif, fps=30)\n",
    "print(f\"Saved GIF to {gif_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def get_intrinsics(H,W):\n",
    "    \"\"\"\n",
    "    Intrinsics for a pinhole camera model.\n",
    "    Assume fov of 55 degrees and central principal point.\n",
    "    \"\"\"\n",
    "    f = 0.5 * W / np.tan(0.5 * 90 * np.pi / 180.0)\n",
    "    cx = 0.5 * W\n",
    "    cy = 0.5 * H\n",
    "    return np.array([[f, 0, cx],\n",
    "                     [0, f, cy],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "def depth_to_points(depth, R=None, t=None):\n",
    "\n",
    "    K = get_intrinsics(depth.shape[0], depth.shape[1])\n",
    "    Kinv = np.linalg.inv(K)\n",
    "    if R is None:\n",
    "        R = np.eye(3)\n",
    "    if t is None:\n",
    "        t = np.zeros(3)\n",
    "\n",
    "    # M converts from your coordinate to PyTorch3D's coordinate system\n",
    "    M = np.eye(3)\n",
    "    M[0, 0] = -1.0\n",
    "    M[1, 1] = -1.0\n",
    "\n",
    "    height, width = depth.shape[0], depth.shape[1]\n",
    "\n",
    "    x = np.arange(width)\n",
    "    y = np.arange(height)\n",
    "    coord = np.stack(np.meshgrid(x, y), -1)\n",
    "    coord = np.concatenate((coord, np.ones_like(coord)[:, :, [0]]), -1)  # z=1\n",
    "    coord = coord.astype(np.float32)\n",
    "    # coord = torch.as_tensor(coord, dtype=torch.float32, device=device)\n",
    "    coord = coord[None]  # bs, h, w, 3\n",
    "    # convert depth from hxw to 1xhxw\n",
    "    depth_convert = depth[None, :, :]\n",
    "\n",
    "    D = depth_convert[:, :, :, None, None]\n",
    "    # print(D.shape, Kinv[None, None, None, ...].shape, coord[:, :, :, :, None].shape )\n",
    "    pts3D_1 = D * Kinv[None, None, None, ...] @ coord[:, :, :, :, None]\n",
    "    # pts3D_1 live in your coordinate system. Convert them to Py3D's\n",
    "    pts3D_1 = M[None, None, None, ...] @ pts3D_1\n",
    "    # from reference to targe tviewpoint\n",
    "    pts3D_2 = R[None, None, None, ...] @ pts3D_1 + t[None, None, None, :, None]\n",
    "    # pts3D_2 = pts3D_1\n",
    "    # depth_2 = pts3D_2[:, :, :, 2, :]  # b,1,h,w\n",
    "    return pts3D_2[:, :, :, :3, 0][0]\n",
    "\n",
    "\n",
    "def create_triangles(h, w, mask=None):\n",
    "    \"\"\"\n",
    "    Reference: https://github.com/google-research/google-research/blob/e96197de06613f1b027d20328e06d69829fa5a89/infinite_nature/render_utils.py#L68\n",
    "    Creates mesh triangle indices from a given pixel grid size.\n",
    "        This function is not and need not be differentiable as triangle indices are\n",
    "        fixed.\n",
    "    Args:\n",
    "    h: (int) denoting the height of the image.\n",
    "    w: (int) denoting the width of the image.\n",
    "    Returns:\n",
    "    triangles: 2D numpy array of indices (int) with shape (2(W-1)(H-1) x 3)\n",
    "    \"\"\"\n",
    "    x, y = np.meshgrid(range(w - 1), range(h - 1))\n",
    "    tl = y * w + x\n",
    "    tr = y * w + x + 1\n",
    "    bl = (y + 1) * w + x\n",
    "    br = (y + 1) * w + x + 1\n",
    "    triangles = np.array([tl, bl, tr, br, tr, bl])\n",
    "    triangles = np.transpose(triangles, (1, 2, 0)).reshape(\n",
    "        ((w - 1) * (h - 1) * 2, 3))\n",
    "    if mask is not None:\n",
    "        mask = mask.reshape(-1)\n",
    "        triangles = triangles[mask[triangles].all(1)]\n",
    "    return triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/omoruyiatekha/Documents/GitHub/pedTrack/mesh.glb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "from functools import partial\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def depth_edges_mask(depth):\n",
    "    \"\"\"Returns a mask of edges in the depth map.\n",
    "    Args:\n",
    "    depth: 2D numpy array of shape (H, W) with dtype float32.\n",
    "    Returns:\n",
    "    mask: 2D numpy array of shape (H, W) with dtype bool.\n",
    "    \"\"\"\n",
    "    # Compute the x and y gradients of the depth map.\n",
    "    depth_dx, depth_dy = np.gradient(depth)\n",
    "    # Compute the gradient magnitude.\n",
    "    depth_grad = np.sqrt(depth_dx ** 2 + depth_dy ** 2)\n",
    "    # Compute the edge mask.\n",
    "    mask = depth_grad > 0.05\n",
    "    return mask\n",
    "\n",
    "def get_mesh(depth, image, keep_edges=False):\n",
    "    # image.thumbnail((1024,1024))  # limit the size of the input image\n",
    "    pts3d = depth_to_points(depth)\n",
    "    pts3d = pts3d.reshape(-1, 3)\n",
    "\n",
    "    # Create a trimesh mesh from the points\n",
    "    # Each pixel is connected to its 4 neighbors\n",
    "    # colors are the RGB values of the image\n",
    "\n",
    "    verts = pts3d.reshape(-1, 3)\n",
    "    image = np.array(image)\n",
    "    if keep_edges:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1])\n",
    "    else:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1], mask=~depth_edges_mask(depth))\n",
    "    colors = image.reshape(-1, 3)\n",
    "    mesh = trimesh.Trimesh(vertices=verts, faces=triangles, vertex_colors=colors)\n",
    "\n",
    "    # Save as glb in folder\n",
    "    glb_file = \"mesh.glb\"\n",
    "    mesh.export(glb_file)\n",
    "    glb_path = os.path.abspath(glb_file)\n",
    "\n",
    "\n",
    "    return glb_path\n",
    "\n",
    "\n",
    "glb_path = get_mesh(np.array(depth), imageRGB, keep_edges=True)\n",
    "print(glb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1972, 3494, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1972, 3494, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array(image).shape)\n",
    "\n",
    "# convert image to C x H x W\n",
    "imageC = np.array(image).transpose(2, 0, 1)\n",
    "\n",
    "# convert imageC which has an alpha channel to RGB\n",
    "imageRGB = imageC[:3]\n",
    "imageRGB = imageRGB.transpose(1, 2, 0)\n",
    "imageRGB.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1972"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(depth).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenCV to reconstruct the 3D point cloud with the depth map and color image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# convert depth to numpy array\n",
    "depth = np.array(depth)\n",
    "\n",
    "def get_intrinsics(H,W):\n",
    "    \"\"\"\n",
    "    Intrinsics for a pinhole camera model.\n",
    "    Assume fov of 55 degrees and central principal point.\n",
    "    \"\"\"\n",
    "    f = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    cx = 0.5 * W\n",
    "    cy = 0.5 * H\n",
    "    return np.array([[f, 0, cx],\n",
    "                     [0, f, cy],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "\n",
    "disparity = depth\n",
    "\n",
    "intrinsics = get_intrinsics(*depth.shape)\n",
    "Q = np.array([[1, 0, 0, -0.5 * depth.shape[1]],\n",
    "              [0, -1, 0, 0.5 * depth.shape[0]],\n",
    "              [0, 0, 0, -intrinsics[0, 0]],\n",
    "              [0, 0, 1, 0]])\n",
    "\n",
    "points = cv2.reprojectImageTo3D(disparity, Q)\n",
    "colors = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create an Open3D point cloud object\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "# Assign points and colors to the point cloud object\n",
    "pcd.points = o3d.utility.Vector3dVector(points.reshape(-1, 3))  # Flatten the points array\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors.reshape(-1, 3) / 255.0)  # Flatten and normalize the colors array\n",
    "\n",
    "# Estimate normals\n",
    "pcd.estimate_normals()\n",
    "\n",
    "# make point cloud\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "# make mesh\n",
    "mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=9)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
